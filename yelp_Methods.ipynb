{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bow_from_reviews(filename):\n",
    "    text = []\n",
    "    Y = []\n",
    "\n",
    "    with open(filename, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            review = row[1]\n",
    "            stars = row[0]\n",
    "            text.append(review)\n",
    "            if stars == '1':\n",
    "                Y.append(0)\n",
    "            else:\n",
    "                Y.append(1)\n",
    "\n",
    "    print('Creating Vectorizer....')\n",
    "    # create an instance of a TF-IDFVectorizer, using\n",
    "    # (1) the standard 'english' stopword set\n",
    "    # (2) only keeping terms in the vocabulary that occur in at least 1% of documents\n",
    "    # (3) allowing both unigrams and bigrams in the vocabulary (use \"ngram_range=(1,2)\" to do this)\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # create a sparse BOW array from 'text' using vectorizer\n",
    "    X = vectorizer.fit_transform(text)\n",
    "\n",
    "    print('Data shape: ', X.shape)\n",
    "\n",
    "    # you can uncomment this next line if you want to see the full list of tokens in the vocabulary\n",
    "    # print('Vocabulary: ', vectorizer.get_feature_names())\n",
    "    return X, Y, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_classification(X, Y, test_fraction):\n",
    "    print('\\nLogistic Classification:')\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_fraction, random_state=42)\n",
    "    #  set the state of the random number generator so that we get the same results across runs when testing our code\n",
    "\n",
    "    print('Number of training examples: ', X_train.shape[0])\n",
    "    print('Number of testing examples: ', X_test.shape[0])\n",
    "    print('Vocabulary size: ', X_train.shape[1])\n",
    "\n",
    "    # Specify the logistic classifier model\n",
    "    classifier = linear_model.LogisticRegression()\n",
    "\n",
    "    # Train a logistic regression classifier and evaluate accuracy on the training data\n",
    "    print('Training a model with', X_train.shape[0], 'examples.....')\n",
    "    classifier.fit(X_train, Y_train)\n",
    "    print('\\nTraining:')\n",
    "    train_accuracy = classifier.score(X_train, Y_train)\n",
    "    print(' accuracy:', format(100 * train_accuracy, '.2f'))\n",
    "\n",
    "    # Compute and print accuracy and AUC on the test data\n",
    "    print('\\nTesting: ')\n",
    "    test_accuracy = classifier.score(X_test, Y_test)\n",
    "    print(' accuracy:', format(100 * test_accuracy, '.2f'))\n",
    "\n",
    "    class_probabilities = classifier.predict_proba(X_test)\n",
    "    test_auc_score = metrics.roc_auc_score(Y_test, class_probabilities[:, 1]);\n",
    "    print(' AUC value:', format(100 * test_auc_score, '.2f'))\n",
    "\n",
    "    return (classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def support_vector_machine(X, Y, test_fraction):\n",
    "    print('\\nSupport Vector Machine:')\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_fraction, random_state=42)\n",
    "    #  set the state of the random number generator so that we get the same results across runs when testing our code\n",
    "\n",
    "    # Specify the logistic classifier model\n",
    "    classifier = SVC(probability=True)\n",
    "\n",
    "    # Train a logistic regression classifier and evaluate accuracy on the training data\n",
    "    print('Training a model with', X_train.shape[0], 'examples.....')\n",
    "    classifier.fit(X_train, Y_train)\n",
    "    print('\\nTraining:')\n",
    "    train_accuracy = classifier.score(X_train, Y_train)\n",
    "    print(' accuracy:', format(100 * train_accuracy, '.2f'))\n",
    "\n",
    "    # Compute and print accuracy and AUC on the test data\n",
    "    print('\\nTesting: ')\n",
    "    test_accuracy = classifier.score(X_test, Y_test)\n",
    "    print(' accuracy:', format(100 * test_accuracy, '.2f'))\n",
    "\n",
    "    class_probabilities = classifier.predict_proba(X_test)\n",
    "    test_auc_score = metrics.roc_auc_score(Y_test, class_probabilities[:, 1]);\n",
    "    print(' AUC value:', format(100 * test_auc_score, '.2f'))\n",
    "\n",
    "    return (classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_support_vector_machine(X, Y, test_fraction):\n",
    "    print('\\nLinear Support Vector Machine:')\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_fraction, random_state=42)\n",
    "    #  set the state of the random number generator so that we get the same results across runs when testing our code\n",
    "\n",
    "    # Specify the logistic classifier model\n",
    "    classifier = LinearSVC()\n",
    "\n",
    "    # Train a logistic regression classifier and evaluate accuracy on the training data\n",
    "    print('Training a model with', X_train.shape[0], 'examples.....')\n",
    "    classifier.fit(X_train, Y_train)\n",
    "    print('\\nTraining:')\n",
    "    train_accuracy = classifier.score(X_train, Y_train)\n",
    "    print(' accuracy:', format(100 * train_accuracy, '.2f'))\n",
    "\n",
    "    # Compute and print accuracy and AUC on the test data\n",
    "    print('\\nTesting: ')\n",
    "    test_accuracy = classifier.score(X_test, Y_test)\n",
    "    print(' accuracy:', format(100 * test_accuracy, '.2f'))\n",
    "\n",
    "    # class_probabilities = classifier.predict_proba(X_test)\n",
    "    # test_auc_score = metrics.roc_auc_score(Y_test, class_probabilities[:, 1]);\n",
    "    # print(' AUC value:', format(100 * test_auc_score, '.2f'))\n",
    "\n",
    "    return (classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DecisionTree_classification(X, Y, test_fraction):\n",
    "    # should add comments defining what the inputs are what the function does\n",
    "    print('\\nDecisionTree:')\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_fraction, random_state=42)\n",
    "    #  set the state of the random number generator so that we get the same results across runs when testing our code\n",
    "\n",
    "    print('Number of training examples: ', X_train.shape[0])\n",
    "    print('Number of testing examples: ', X_test.shape[0])\n",
    "    print('Vocabulary size: ', X_train.shape[1])\n",
    "\n",
    "    # Specify the logistic classifier model with an l2 penalty for regularization and with fit_intercept turned on\n",
    "    classifier = DecisionTreeClassifier(criterion=\"entropy\",random_state=0)\n",
    "\n",
    "    # Train a logistic regression classifier and evaluate accuracy on the training data\n",
    "    print('\\nTraining a model with', X_train.shape[0], 'examples.....')\n",
    "    classifier.fit(X_train, Y_train)\n",
    "    train_predictions = classifier.predict(X_train)\n",
    "    train_accuracy = classifier.score(X_train, Y_train)\n",
    "    print('\\nTraining:')\n",
    "    print(' accuracy:', format(100 * train_accuracy, '.2f'))\n",
    "\n",
    "    # Compute and print accuracy and AUC on the test data\n",
    "    print('\\nTesting: ')\n",
    "    test_predictions = classifier.predict(X_test)\n",
    "    test_accuracy = classifier.score(X_test, Y_test)\n",
    "    print(' accuracy:', format(100 * test_accuracy, '.2f'))\n",
    "\n",
    "    class_probabilities = classifier.predict_proba(X_test)\n",
    "    test_auc_score = metrics.roc_auc_score(Y_test, class_probabilities[:, 1])\n",
    "    print(' AUC value:', format(100 * test_auc_score, '.2f'))\n",
    "\n",
    "    return (classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_Forest_Classifier(X, Y, test_fraction):\n",
    "    print('\\nRandom_Forest_Classifier:')\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_fraction, random_state=42)\n",
    "    #  set the state of the random number generator so that we get the same results across runs when testing our code\n",
    "\n",
    "    # Specify the logistic classifier model\n",
    "    classifier = RandomForestClassifier(n_estimators=13)\n",
    "\n",
    "    # Train a logistic regression classifier and evaluate accuracy on the training data\n",
    "    print('Training a model with', X_train.shape[0], 'examples.....')\n",
    "    classifier.fit(X_train, Y_train)\n",
    "    print('\\nTraining:')\n",
    "    train_accuracy = classifier.score(X_train, Y_train)\n",
    "    print(' accuracy:', format(100 * train_accuracy, '.2f'))\n",
    "\n",
    "    # Compute and print accuracy and AUC on the test data\n",
    "    print('\\nTesting: ')\n",
    "    test_accuracy = classifier.score(X_test, Y_test)\n",
    "    print(' accuracy:', format(100 * test_accuracy, '.2f'))\n",
    "\n",
    "    # class_probabilities = classifier.predict_proba(X_test)\n",
    "    # test_auc_score = metrics.roc_auc_score(Y_test, class_probabilities[:, 1]);\n",
    "    # print(' AUC value:', format(100 * test_auc_score, '.2f'))\n",
    "\n",
    "    return (classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Naive_Bayes_Classifier(X, Y, test_fraction):\n",
    "    print('\\nNaive_Bayes_Classifier:')\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_fraction, random_state=42)\n",
    "    #  set the state of the random number generator so that we get the same results across runs when testing our code\n",
    "\n",
    "    # Specify the logistic classifier model\n",
    "    classifier = MultinomialNB()\n",
    "\n",
    "    # Train a logistic regression classifier and evaluate accuracy on the training data\n",
    "    print('Training a model with', X_train.shape[0], 'examples.....')\n",
    "    classifier.fit(X_train, Y_train)\n",
    "    print('\\nTraining:')\n",
    "    train_accuracy = classifier.score(X_train, Y_train)\n",
    "    print(' accuracy:', format(100 * train_accuracy, '.2f'))\n",
    "\n",
    "    # Compute and print accuracy and AUC on the test data\n",
    "    print('\\nTesting: ')\n",
    "    test_accuracy = classifier.score(X_test, Y_test)\n",
    "    print(' accuracy:', format(100 * test_accuracy, '.2f'))\n",
    "\n",
    "    # class_probabilities = classifier.predict_proba(X_test)\n",
    "    # test_auc_score = metrics.roc_auc_score(Y_test, class_probabilities[:, 1]);\n",
    "    # print(' AUC value:', format(100 * test_auc_score, '.2f'))\n",
    "\n",
    "    return (classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_significant_terms(classifier, vectorizer, K):\n",
    "    # find the largest K positive/negative weights' INDICES!\n",
    "    coefs = classifier.coef_[0]\n",
    "    topK_pos_indices = np.argsort(coefs)[-K:];\n",
    "    topK_neg_indices = np.argsort(coefs)[0:K];\n",
    "\n",
    "    topK_pos_weights = []\n",
    "    topK_neg_weights = []\n",
    "    topK_pos_terms = []\n",
    "    topK_neg_terms = []\n",
    "\n",
    "    # cycle through the indices, in the order of largest weight first\n",
    "    # 1) append the weight and term to lists\n",
    "    # 2) print K lines:\n",
    "    #     (a) the term corresponding to the weight (a string)\n",
    "    #     (b) the weight value itself (a scalar printed to 3 decimal places)\n",
    "    print('Most significant positive terms & weight:')\n",
    "    for i in topK_pos_indices[::-1]:\n",
    "        weight = coefs[i]\n",
    "        term = vectorizer.get_feature_names()[i]\n",
    "        topK_pos_weights.append(weight)\n",
    "        topK_pos_terms.append(term)\n",
    "        print('term: {:<15}, weight = {:.4f}'.format(term, weight))\n",
    "\n",
    "    print('Most significant negative terms & weight:')\n",
    "    for i in topK_neg_indices:\n",
    "        weight = coefs[i]\n",
    "        term = vectorizer.get_feature_names()[i]\n",
    "        topK_neg_weights.append(weight)\n",
    "        topK_neg_terms.append(term)\n",
    "        print('term: {:<15}, weight = {:.4f}'.format(term, weight))\n",
    "\n",
    "    return (topK_pos_weights, topK_neg_weights, topK_pos_terms, topK_neg_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Vectorizer....\n",
      "Data shape:  (560000, 224898)\n",
      "\n",
      "Logistic Classification:\n",
      "Number of training examples:  280000\n",
      "Number of testing examples:  280000\n",
      "Vocabulary size:  224898\n",
      "Training a model with 280000 examples.....\n",
      "\n",
      "Training:\n",
      " accuracy: 94.40\n",
      "\n",
      "Testing: \n",
      " accuracy: 93.21\n",
      " AUC value: 98.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "X, Y, vectorizer_BOW = create_bow_from_reviews('train.csv')\n",
    "test_fraction = 0.5\n",
    "logistic_classifier = logistic_classification(X, Y, test_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DecisionTree:\n",
      "Number of training examples:  280000\n",
      "Number of testing examples:  280000\n",
      "Vocabulary size:  224898\n",
      "\n",
      "Training a model with 280000 examples.....\n"
     ]
    }
   ],
   "source": [
    "DecisionTree_classifier = DecisionTree_classification(X, Y,test_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "LSVC = linear_support_vector_machine(X, Y, test_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "RandomForestClassifier = Random_Forest_Classifier(X, Y,test_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "NaiveBayesClassifier = Naive_Bayes_Classifier(X, Y,test_fraction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}