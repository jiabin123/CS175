{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bow_from_reviews(filename):\n",
    "    print('Loading the file:', filename)\n",
    "    with open(filename, 'r') as jfile:\n",
    "        data = json.load(jfile)\n",
    "    print('Total number of reviews extracted =', len(data))\n",
    "    text = []\n",
    "    Y = []\n",
    "    print('Extracting tokens from each review.....(can be slow for a large number of reviews)......')\n",
    "    for d in data:  # can substitute data[0:9] here if you want to test this function on just a few reviews\n",
    "        review = d['review']\n",
    "        stars = int(d['rating'])\n",
    "        if stars > 5:  # represent scores > 5 as \"1\" / positive\n",
    "            score = 1\n",
    "        else:          # represent scores > 5 as \"0\" / negative\n",
    "            score = 0\n",
    "\n",
    "        text.append(review)\n",
    "        Y.append(score)\n",
    "\n",
    "    # create an instance of a TF-IDFVectorizer, using\n",
    "    # (1) the standard 'english' stopword set\n",
    "    # (2) only keeping terms in the vocabulary that occur in at least 1% of documents\n",
    "    # (3) allowing both unigrams and bigrams in the vocabulary (use \"ngram_range=(1,2)\" to do this)\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # create a sparse BOW array from 'text' using vectorizer\n",
    "    X = vectorizer.fit_transform(text)\n",
    "\n",
    "    print('Data shape: ', X.shape)\n",
    "\n",
    "    # you can uncomment this next line if you want to see the full list of tokens in the vocabulary\n",
    "    # print('Vocabulary: ', vectorizer.get_feature_names())\n",
    "    return X, Y, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_classification(X, Y, test_fraction):\n",
    "    print('\\nLogistic Classification:')\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_fraction, random_state=42)\n",
    "    #  set the state of the random number generator so that we get the same results across runs when testing our code\n",
    "\n",
    "    print('Number of training examples: ', X_train.shape[0])\n",
    "    print('Number of testing examples: ', X_test.shape[0])\n",
    "    print('Vocabulary size: ', X_train.shape[1])\n",
    "\n",
    "    # Specify the logistic classifier model\n",
    "    classifier = linear_model.LogisticRegression()\n",
    "\n",
    "    # Train a logistic regression classifier and evaluate accuracy on the training data\n",
    "    print('Training a model with', X_train.shape[0], 'examples.....')\n",
    "    classifier.fit(X_train, Y_train)\n",
    "    print('\\nTraining:')\n",
    "    train_accuracy = classifier.score(X_train, Y_train)\n",
    "    print(' accuracy:', format(100 * train_accuracy, '.2f'))\n",
    "\n",
    "    # Compute and print accuracy and AUC on the test data\n",
    "    print('\\nTesting: ')\n",
    "    test_accuracy = classifier.score(X_test, Y_test)\n",
    "    print(' accuracy:', format(100 * test_accuracy, '.2f'))\n",
    "\n",
    "    class_probabilities = classifier.predict_proba(X_test)\n",
    "    test_auc_score = metrics.roc_auc_score(Y_test, class_probabilities[:, 1]);\n",
    "    print(' AUC value:', format(100 * test_auc_score, '.2f'))\n",
    "\n",
    "    return (classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def support_vector_machine(X, Y, test_fraction):\n",
    "    print('\\nSupport Vector Machine:')\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_fraction, random_state=42)\n",
    "    #  set the state of the random number generator so that we get the same results across runs when testing our code\n",
    "\n",
    "    # Specify the logistic classifier model\n",
    "    classifier = SVC(probability=True)\n",
    "\n",
    "    # Train a logistic regression classifier and evaluate accuracy on the training data\n",
    "    print('Training a model with', X_train.shape[0], 'examples.....')\n",
    "    classifier.fit(X_train, Y_train)\n",
    "    print('\\nTraining:')\n",
    "    train_accuracy = classifier.score(X_train, Y_train)\n",
    "    print(' accuracy:', format(100 * train_accuracy, '.2f'))\n",
    "\n",
    "    # Compute and print accuracy and AUC on the test data\n",
    "    print('\\nTesting: ')\n",
    "    test_accuracy = classifier.score(X_test, Y_test)\n",
    "    print(' accuracy:', format(100 * test_accuracy, '.2f'))\n",
    "\n",
    "    class_probabilities = classifier.predict_proba(X_test)\n",
    "    test_auc_score = metrics.roc_auc_score(Y_test, class_probabilities[:, 1]);\n",
    "    print(' AUC value:', format(100 * test_auc_score, '.2f'))\n",
    "\n",
    "    return (classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_support_vector_machine(X, Y, test_fraction):\n",
    "    print('\\nLinear Support Vector Machine:')\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_fraction, random_state=42)\n",
    "    #  set the state of the random number generator so that we get the same results across runs when testing our code\n",
    "\n",
    "    # Specify the logistic classifier model\n",
    "    classifier = LinearSVC()\n",
    "\n",
    "    # Train a logistic regression classifier and evaluate accuracy on the training data\n",
    "    print('Training a model with', X_train.shape[0], 'examples.....')\n",
    "    classifier.fit(X_train, Y_train)\n",
    "    print('\\nTraining:')\n",
    "    train_accuracy = classifier.score(X_train, Y_train)\n",
    "    print(' accuracy:', format(100 * train_accuracy, '.2f'))\n",
    "\n",
    "    # Compute and print accuracy and AUC on the test data\n",
    "    print('\\nTesting: ')\n",
    "    test_accuracy = classifier.score(X_test, Y_test)\n",
    "    print(' accuracy:', format(100 * test_accuracy, '.2f'))\n",
    "\n",
    "    # class_probabilities = classifier.predict_proba(X_test)\n",
    "    # test_auc_score = metrics.roc_auc_score(Y_test, class_probabilities[:, 1]);\n",
    "    # print(' AUC value:', format(100 * test_auc_score, '.2f'))\n",
    "\n",
    "    return (classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DecisionTree_classification(X, Y, test_fraction):\n",
    "    # should add comments defining what the inputs are what the function does\n",
    "    print('\\nDecisionTree:')\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_fraction, random_state=42)\n",
    "    #  set the state of the random number generator so that we get the same results across runs when testing our code\n",
    "\n",
    "    print('Number of training examples: ', X_train.shape[0])\n",
    "    print('Number of testing examples: ', X_test.shape[0])\n",
    "    print('Vocabulary size: ', X_train.shape[1])\n",
    "\n",
    "    # Specify the logistic classifier model with an l2 penalty for regularization and with fit_intercept turned on\n",
    "    classifier = DecisionTreeClassifier(criterion=\"entropy\",random_state=0)\n",
    "\n",
    "    # Train a logistic regression classifier and evaluate accuracy on the training data\n",
    "    print('\\nTraining a model with', X_train.shape[0], 'examples.....')\n",
    "    classifier.fit(X_train, Y_train)\n",
    "    train_predictions = classifier.predict(X_train)\n",
    "    train_accuracy = classifier.score(X_train, Y_train)\n",
    "    print('\\nTraining:')\n",
    "    print(' accuracy:', format(100 * train_accuracy, '.2f'))\n",
    "\n",
    "    # Compute and print accuracy and AUC on the test data\n",
    "    print('\\nTesting: ')\n",
    "    test_predictions = classifier.predict(X_test)\n",
    "    test_accuracy = classifier.score(X_test, Y_test)\n",
    "    print(' accuracy:', format(100 * test_accuracy, '.2f'))\n",
    "\n",
    "    class_probabilities = classifier.predict_proba(X_test)\n",
    "    test_auc_score = metrics.roc_auc_score(Y_test, class_probabilities[:, 1])\n",
    "    print(' AUC value:', format(100 * test_auc_score, '.2f'))\n",
    "\n",
    "    return (classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_Forest_Classifier(X, Y, test_fraction):\n",
    "    print('\\nRandom_Forest_Classifier:')\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_fraction, random_state=42)\n",
    "    #  set the state of the random number generator so that we get the same results across runs when testing our code\n",
    "\n",
    "    # Specify the logistic classifier model\n",
    "    classifier = RandomForestClassifier(n_estimators=13)\n",
    "\n",
    "    # Train a logistic regression classifier and evaluate accuracy on the training data\n",
    "    print('Training a model with', X_train.shape[0], 'examples.....')\n",
    "    classifier.fit(X_train, Y_train)\n",
    "    print('\\nTraining:')\n",
    "    train_accuracy = classifier.score(X_train, Y_train)\n",
    "    print(' accuracy:', format(100 * train_accuracy, '.2f'))\n",
    "\n",
    "    # Compute and print accuracy and AUC on the test data\n",
    "    print('\\nTesting: ')\n",
    "    test_accuracy = classifier.score(X_test, Y_test)\n",
    "    print(' accuracy:', format(100 * test_accuracy, '.2f'))\n",
    "\n",
    "    # class_probabilities = classifier.predict_proba(X_test)\n",
    "    # test_auc_score = metrics.roc_auc_score(Y_test, class_probabilities[:, 1]);\n",
    "    # print(' AUC value:', format(100 * test_auc_score, '.2f'))\n",
    "\n",
    "    return (classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Naive_Bayes_Classifier(X, Y, test_fraction):\n",
    "    print('\\nNaive_Bayes_Classifier:')\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_fraction, random_state=42)\n",
    "    #  set the state of the random number generator so that we get the same results across runs when testing our code\n",
    "\n",
    "    # Specify the logistic classifier model\n",
    "    classifier = MultinomialNB()\n",
    "\n",
    "    # Train a logistic regression classifier and evaluate accuracy on the training data\n",
    "    print('Training a model with', X_train.shape[0], 'examples.....')\n",
    "    classifier.fit(X_train, Y_train)\n",
    "    print('\\nTraining:')\n",
    "    train_accuracy = classifier.score(X_train, Y_train)\n",
    "    print(' accuracy:', format(100 * train_accuracy, '.2f'))\n",
    "\n",
    "    # Compute and print accuracy and AUC on the test data\n",
    "    print('\\nTesting: ')\n",
    "    test_accuracy = classifier.score(X_test, Y_test)\n",
    "    print(' accuracy:', format(100 * test_accuracy, '.2f'))\n",
    "\n",
    "    # class_probabilities = classifier.predict_proba(X_test)\n",
    "    # test_auc_score = metrics.roc_auc_score(Y_test, class_probabilities[:, 1]);\n",
    "    # print(' AUC value:', format(100 * test_auc_score, '.2f'))\n",
    "\n",
    "    return (classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_significant_terms(classifier, vectorizer, K):\n",
    "    # find the largest K positive/negative weights' INDICES!\n",
    "    coefs = classifier.coef_[0]\n",
    "    topK_pos_indices = np.argsort(coefs)[-K:];\n",
    "    topK_neg_indices = np.argsort(coefs)[0:K];\n",
    "\n",
    "    topK_pos_weights = []\n",
    "    topK_neg_weights = []\n",
    "    topK_pos_terms = []\n",
    "    topK_neg_terms = []\n",
    "\n",
    "    # cycle through the indices, in the order of largest weight first\n",
    "    # 1) append the weight and term to lists\n",
    "    # 2) print K lines:\n",
    "    #     (a) the term corresponding to the weight (a string)\n",
    "    #     (b) the weight value itself (a scalar printed to 3 decimal places)\n",
    "    print('Most significant positive terms & weight:')\n",
    "    for i in topK_pos_indices[::-1]:\n",
    "        weight = coefs[i]\n",
    "        term = vectorizer.get_feature_names()[i]\n",
    "        topK_pos_weights.append(weight)\n",
    "        topK_pos_terms.append(term)\n",
    "        print('term: {:<15}, weight = {:.4f}'.format(term, weight))\n",
    "\n",
    "    print('Most significant negative terms & weight:')\n",
    "    for i in topK_neg_indices:\n",
    "        weight = coefs[i]\n",
    "        term = vectorizer.get_feature_names()[i]\n",
    "        topK_neg_weights.append(weight)\n",
    "        topK_neg_terms.append(term)\n",
    "        print('term: {:<15}, weight = {:.4f}'.format(term, weight))\n",
    "\n",
    "    return (topK_pos_weights, topK_neg_weights, topK_pos_terms, topK_neg_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the file: review.json\n",
      "Total number of reviews extracted = 50000\n",
      "Extracting tokens from each review.....(can be slow for a large number of reviews)......\n",
      "Data shape:  (50000, 101895)\n",
      "\n",
      "Logistic Classification:\n",
      "Number of training examples:  25000\n",
      "Number of testing examples:  25000\n",
      "Vocabulary size:  101895\n",
      "Training a model with 25000 examples.....\n",
      "\n",
      "Training:\n",
      " accuracy: 84.81\n",
      "\n",
      "Testing: \n",
      " accuracy: 77.43\n",
      " AUC value: 84.19\n"
     ]
    }
   ],
   "source": [
    "X, Y, vectorizer_BOW = create_bow_from_reviews('review.json')\n",
    "test_fraction = 0.5\n",
    "logistic_classifier = logistic_classification(X, Y, test_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DecisionTree:\n",
      "Number of training examples:  25000\n",
      "Number of testing examples:  25000\n",
      "Vocabulary size:  101895\n",
      "\n",
      "Training a model with 25000 examples.....\n",
      "\n",
      "Training:\n",
      " accuracy: 100.00\n",
      "\n",
      "Testing: \n",
      " accuracy: 65.92\n",
      " AUC value: 59.91\n"
     ]
    }
   ],
   "source": [
    "DecisionTree_classifier = DecisionTree_classification(X, Y,test_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear Support Vector Machine:\n",
      "Training a model with 25000 examples.....\n",
      "\n",
      "Training:\n",
      " accuracy: 96.91\n",
      "\n",
      "Testing: \n",
      " accuracy: 76.62\n"
     ]
    }
   ],
   "source": [
    "LSVC = linear_support_vector_machine(X, Y, test_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random_Forest_Classifier:\n",
      "Training a model with 25000 examples.....\n",
      "\n",
      "Training:\n",
      " accuracy: 99.23\n",
      "\n",
      "Testing: \n",
      " accuracy: 70.97\n"
     ]
    }
   ],
   "source": [
    "RandomForestClassifier = Random_Forest_Classifier(X, Y,test_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive_Bayes_Classifier:\n",
      "Training a model with 25000 examples.....\n",
      "\n",
      "Training:\n",
      " accuracy: 69.17\n",
      "\n",
      "Testing: \n",
      " accuracy: 69.97\n"
     ]
    }
   ],
   "source": [
    "NaiveBayesClassifier = Naive_Bayes_Classifier(X, Y,test_fraction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
