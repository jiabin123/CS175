{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading the file: \n",
      " reviews.json\n",
      "\n",
      "Total number of reviews extracted = 1000\n",
      "\n",
      "Extracting tokens from each review.....(can be slow for a large number of reviews)......\n",
      "Data shape:  (1000, 1819)\n",
      "Number of training examples:  500\n",
      "Number of testing examples:  500\n",
      "Vocabulary size:  1819\n",
      "\n",
      "Training a model with 500 examples.....\n",
      "\n",
      "Training:\n",
      " accuracy: 100.00\n",
      "\n",
      "Testing: \n",
      " accuracy: 67.40\n",
      " AUC value: 61.10\n"
     ]
    }
   ],
   "source": [
    "# This is a sample Python script.\n",
    "\n",
    "# Press Shift+F10 to execute it or replace it with your code.\n",
    "# Press Double Shift to search everywhere for classes, files, tool windows, actions, and settings.\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "import simplejson as jsoncm\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def create_bow_from_reviews(filename, min_pos=7, max_neg=4):\n",
    "    print('\\nLoading the file: \\n', filename)\n",
    "    with open(filename, 'r') as jfile:\n",
    "        data = jsoncm.load(jfile)\n",
    "    print('\\nTotal number of reviews extracted =', len(data))\n",
    "\n",
    "    text = []\n",
    "    Y = []\n",
    "    lengths = []\n",
    "    print('\\nExtracting tokens from each review.....(can be slow for a large number of reviews)......')\n",
    "    for d in data:  # can substitute data[0:9] here if you want to test this function on just a few reviews\n",
    "        review = d['review']  # keep only the text and label\n",
    "        stars = d['rating']\n",
    "        # ....write some simple logic to generate a binary score for each review\n",
    "        if stars >= min_pos:\n",
    "            score = 1\n",
    "            text.append(review)\n",
    "            Y.append(score)\n",
    "        elif stars <= max_neg:\n",
    "            score = 0\n",
    "            text.append(review)\n",
    "            Y.append(score)\n",
    "\n",
    "    # create an instance of a CountVectorizer, using\n",
    "    # (1) the standard 'english' stopword set\n",
    "    # (2) only keeping terms in the vocabulary that occur in at least 1% of documents\n",
    "    # (3) allowing both unigrams and bigrams in the vocabulary (use \"ngram_range=(1,2)\" to do this)\n",
    "    vectorizer = CountVectorizer(stop_words='english', min_df=0.01, ngram_range=(1, 2))\n",
    "\n",
    "    # create a sparse BOW array from 'text' using vectorizer\n",
    "    X = vectorizer.fit_transform(text)\n",
    "\n",
    "    # an alternative above would be to use TfIDF rather than counts - which is very simple to do (but not needed here)\n",
    "\n",
    "    print('Data shape: ', X.shape)\n",
    "\n",
    "    # you can uncomment this next line if you want to see the full list of tokens in the vocabulary\n",
    "    # print('Vocabulary: ', vectorizer.get_feature_names())\n",
    "\n",
    "    return X, Y, vectorizer\n",
    "\n",
    "\n",
    "\n",
    "def DecisionTree_classification(X, Y, test_fraction):\n",
    "    # should add comments defining what the inputs are what the function does\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_fraction, random_state=42)\n",
    "    #  set the state of the random number generator so that we get the same results across runs when testing our code\n",
    "\n",
    "    print('Number of training examples: ', X_train.shape[0])\n",
    "    print('Number of testing examples: ', X_test.shape[0])\n",
    "    print('Vocabulary size: ', X_train.shape[1])\n",
    "\n",
    "    # Specify the logistic classifier model with an l2 penalty for regularization and with fit_intercept turned on\n",
    "    classifier = DecisionTreeClassifier(criterion=\"entropy\",random_state=0)\n",
    "\n",
    "    # Train a logistic regression classifier and evaluate accuracy on the training data\n",
    "    print('\\nTraining a model with', X_train.shape[0], 'examples.....')\n",
    "    classifier.fit(X_train, Y_train)\n",
    "    train_predictions = classifier.predict(X_train)\n",
    "    train_accuracy = classifier.score(X_train, Y_train)\n",
    "    print('\\nTraining:')\n",
    "    print(' accuracy:', format(100 * train_accuracy, '.2f'))\n",
    "\n",
    "    # Compute and print accuracy and AUC on the test data\n",
    "    print('\\nTesting: ')\n",
    "    test_predictions = classifier.predict(X_test)\n",
    "    test_accuracy = classifier.score(X_test, Y_test)\n",
    "    print(' accuracy:', format(100 * test_accuracy, '.2f'))\n",
    "\n",
    "    class_probabilities = classifier.predict_proba(X_test)\n",
    "    test_auc_score = metrics.roc_auc_score(Y_test, class_probabilities[:, 1])\n",
    "    print(' AUC value:', format(100 * test_auc_score, '.2f'))\n",
    "\n",
    "    return (classifier)\n",
    "\n",
    "\n",
    "X, Y , vectorizer_BOW = create_bow_from_reviews('reviews.json')\n",
    "# run a decision Tree classifier on the reviews, specifying the fraction to be used for testing\n",
    "test_fraction = 0.5\n",
    "DecisionTree_classifier = DecisionTree_classification(X, Y,test_fraction)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
